{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21014135",
   "metadata": {},
   "source": [
    "# Pouliot and Torgovitsky Research Professional Test - Alexander Quispe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8651b440",
   "metadata": {},
   "source": [
    "$$Y_i = arg\\max_{ j=0, 1..., J } (\\alpha_j + \\beta*p_j + U_{ij} )$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a53da59b",
   "metadata": {},
   "source": [
    "## 1. Use the following information to solve for $\\beta$ to within three decimal places:\n",
    "\n",
    "j | alpha_j | p_j | P[Y_i = j] \n",
    "--|---------|-----|------------\n",
    "0 | 0 | 0 | 0.427\n",
    "1 | -0.5 | 5 | 0.157\n",
    "2 | 0 | 10 | 0.157\n",
    "3 | 1 | 15 | 0.259\n",
    "\n",
    "\n",
    "In a multinomial logit model, the probabilities of each outcome can be represented as:\n",
    "\n",
    "$$ P[Y_i = j] = exp(alpha_j + \\beta**p_j) / \\sum(exp(alpha_k + \\beta*p_k)) $$\n",
    "\n",
    "for all k, where the sum runs over all possible choices.\n",
    "From the information given, we have four equations:\n",
    "\n",
    "* $$ exp(\\alpha_0 + \\beta*p_0) / \\sum(exp(\\alpha_k + \\beta_k)) = 0.427 $$\n",
    "* $$ exp(\\alpha_1 + \\beta*p_1) / \\sum(exp(\\alpha_k + \\beta_k)) = 0.157 $$\n",
    "* $$ exp(\\alpha_2 + \\beta*p_2) / \\sum(exp(\\alpha_k + \\beta_k)) = 0.157 $$\n",
    "* $$ exp(\\alpha_3 + \\beta*p_3) / \\sum(exp(\\alpha_k + \\beta_k)) = 0.259 $$\n",
    "\n",
    "Using the information in the table above\n",
    "\n",
    "* $$ 1 / (1 + exp(-0.5 + \\beta*5) + exp(\\beta*10) + exp(1 + \\beta**15)) = 0.427  $$\n",
    "* $$ exp(-0.5 + \\beta*5) / (1 + exp(-0.5 + \\beta*5) + exp(\\beta*10) + exp(1 + \\beta*15)) = 0.157 $$\n",
    "* $$ exp(\\beta*10) / (1 + exp(-0.5 + \\beta*5) + exp(\\beta*10) + exp(1 + \\beta*15)) = 0.157 $$\n",
    "* $$ exp(1 + \\beta*15) / (1 + exp(-0.5 + \\beta*5) + exp(\\beta*10) + exp(1 + \\beta*15)) = 0.259 $$\n",
    "\n",
    "We can use these equations to solve for Beta. However, this is a nonlinear equation system and it might not have a simple closed-form solution, so a numerical solution method might be needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06975779",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Estimated value of Beta: -0.10002526231193\"\n"
     ]
    }
   ],
   "source": [
    "# install.packages(\"rootSolve\")\n",
    "library(rootSolve)\n",
    "\n",
    "# define the function where we want to find the roots\n",
    "eqn <- function(Beta) {\n",
    "  return (1 / (1 + exp(-0.5 + Beta*5) + exp(Beta*10) + exp(1 + Beta*15)) - 0.427)\n",
    "}\n",
    "\n",
    "# initial guess for Beta\n",
    "Beta_init <- 0\n",
    "\n",
    "sol <- multiroot(eqn, start = Beta_init)\n",
    "Beta <- sol$root[1]\n",
    "print(paste(\"Estimated value of Beta:\", Beta))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2bb0a06b",
   "metadata": {},
   "source": [
    "## 2.  Write a function that computes the log-likelihood "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c9a877f-d4c4-41e2-a07c-1655fef40951",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] -5.904516\n"
     ]
    }
   ],
   "source": [
    "# Define the function that computes the log-likelihood for the entire sample\n",
    "log_likelihood <- function(alpha, Beta, Y, p) {\n",
    "  J <- length(alpha)\n",
    "  n <- length(Y)\n",
    "  logL <- 0\n",
    "  for (i in 1:n) {\n",
    "      rest <- 0\n",
    "      for(j in 1:J){\n",
    "          rest <- rest + sum(exp(alpha[j] + Beta*p[j]))\n",
    "      }\n",
    "    logL <- logL + alpha[i] + Beta*p[i] - log(rest)\n",
    "  }\n",
    "  return(logL)\n",
    "}\n",
    "\n",
    "# Values of alpha, Beta, and p from the table\n",
    "alpha <- c(0, -0.5, 0, 1)\n",
    "Beta <- -0.1  # Beta value found\n",
    "p <- c(0, 5, 10, 15)\n",
    "\n",
    "# Your sample of realizations\n",
    "Y <- c(0, 1, 2, 3)  # This is our sample\n",
    "\n",
    "# Compute the log-likelihood for this sample\n",
    "logL <- log_likelihood(alpha, Beta, Y, p)\n",
    "print(logL)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71dc58d5",
   "metadata": {},
   "source": [
    "## 3. Write a function that maximizes the log-likelihood in the previous part.\n",
    "In this example, I'm using the 'Nelder-Mead' method as it's a good general-purpose optimizer, especially when the function we're optimizing is relatively smooth, which is the case for many log-likelihood functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aef442b7-a339-4c44-9610-173f78554917",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Optimized alpha:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>-0.509438512010376</li><li>-0.2207901803004</li><li>0.0685582625214819</li><li>0.357396302057347</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item -0.509438512010376\n",
       "\\item -0.2207901803004\n",
       "\\item 0.0685582625214819\n",
       "\\item 0.357396302057347\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. -0.509438512010376\n",
       "2. -0.2207901803004\n",
       "3. 0.0685582625214819\n",
       "4. 0.357396302057347\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] -0.50943851 -0.22079018  0.06855826  0.35739630"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Optimized beta:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "-0.0577985244965928"
      ],
      "text/latex": [
       "-0.0577985244965928"
      ],
      "text/markdown": [
       "-0.0577985244965928"
      ],
      "text/plain": [
       "[1] -0.05779852"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your sample of realizations\n",
    "Y_p = 1:4  # replace this with your actual data\n",
    "\n",
    "# Values of p from the table\n",
    "p_p = c(0, 5, 10, 15)\n",
    "Beta = 4\n",
    "\n",
    "# Initial guess for alpha and Beta\n",
    "params_init = c(0, -0.5, 0, 1, 0.0)  # The first four values are for alpha and the last for beta\n",
    "\n",
    "neg_log_likelihood <- function(params, Y = Y_p, p = p_p) {\n",
    "  alpha <- params[-length(params)]  # all but the last entry\n",
    "  Beta <- params[length(params)]  # the last entry\n",
    "  J <- length(alpha)\n",
    "  n <- length(Y)\n",
    "  logL <- 0\n",
    "  for (i in 1:n) {\n",
    "    inner_sum <- 0\n",
    "    for (j in 1:J) {\n",
    "      inner_sum <- inner_sum + exp(alpha[j] + Beta*p[j])\n",
    "    }\n",
    "    logL <- logL + alpha[Y[i]] + Beta*p[Y[i]] - log(inner_sum)\n",
    "  }\n",
    "  return(-logL)  # we return the negative log-likelihood\n",
    "}\n",
    "\n",
    "res <- optim(params_init, fn = neg_log_likelihood,  method = \"Nelder-Mead\")\n",
    "alpha <- res$par[1:length(Y)]\n",
    "beta_opt <- res$par[length(params_init)]\n",
    "print(paste(\"Optimized alpha:\"))\n",
    "alpha\n",
    "print(paste(\"Optimized beta:\"))\n",
    "beta_opt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ebb0a89f",
   "metadata": {},
   "source": [
    "### explain why you used the package **optim: General-purpose Optimization**\n",
    "* **Robustness**: The log-likelihood function may not be globally concave, and might have multiple local maxima. The optimization algorithms implemented in scipy.optimize.minimize are capable of handling such non-convex problems.\n",
    "\n",
    "* **Numerical Methods**: Real-world econometric applications often involve complex models for which analytical solutions are not available, requiring the use of numerical methods. scipy.optimize.minimize uses numerical optimization algorithms, making it a useful tool for such applications.\n",
    "\n",
    "* **Scalability**: The task of optimizing the log-likelihood function may become computationally demanding as the size of the dataset (number of observations) increases. The algorithms in scipy.optimize.minimize are designed to handle large-scale problems efficiently."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76a11d2f",
   "metadata": {},
   "source": [
    "## 4. Construct an estimator $\\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f51e5a21",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta_hat: 0.00053648 \n"
     ]
    }
   ],
   "source": [
    "# Define the function that calculates theta_hat\n",
    "calculate_theta_hat <- function(alpha_hat, Beta_hat, p) {\n",
    "  J <- length(alpha_hat)\n",
    "  \n",
    "  # Calculate utilities for all choices\n",
    "  utilities <- sapply(1:J, function(j) alpha_hat[j] + Beta_hat * p[j])\n",
    "  \n",
    "  # Utility for choice 1 with altered price p1 (p1=3)\n",
    "  utility_1_altered <- alpha_hat[2] + 3 * Beta_hat  # Adjust the index if necessary\n",
    "  \n",
    "  # Calculate the probabilities for each choice\n",
    "  probabilities <- exp(utilities)\n",
    "  probabilities[2] <- exp(utility_1_altered)  # replace with altered utility for choice 1\n",
    "  \n",
    "  # Normalize the probabilities so they sum to 1\n",
    "  probabilities <- probabilities / sum(probabilities)\n",
    "  \n",
    "  # theta_hat is the probability for choice 1\n",
    "  theta_hat <- probabilities[2]  # Adjust the index if necessary\n",
    "  \n",
    "  return(theta_hat)\n",
    "}\n",
    "\n",
    "# Let's use some estimated parameters alpha_hat and Beta_hat for demonstration\n",
    "alpha_hat <- c(0, -0.5, 0, 1)\n",
    "Beta_hat <- 0.5\n",
    "\n",
    "# Values of p from the table\n",
    "p <- c(0, 5, 10, 15)\n",
    "\n",
    "theta_hat <- calculate_theta_hat(alpha_hat, Beta_hat, p)\n",
    "\n",
    "cat(\"theta_hat:\", format(theta_hat, digits = 5), \"\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5098976",
   "metadata": {},
   "source": [
    "## Provide an economic interpretation of $\\theta$\n",
    "\n",
    "* In this excercise, θ represents the probability that a specific option, in this case option 1, would provide the highest utility for an individual given a specific alteration (the price of option 1 being 3 instead of 5).\n",
    "\n",
    "* Economically, this can be interpreted as the likelihood of a consumer preferring and therefore choosing option 1 over all other available options when the price of option 1 is reduced. Essentially, θ represents the shift in consumer preference when the price of option 1 changes.\n",
    "\n",
    "* The term \"utility\" here represents the satisfaction or benefit a consumer receives from choosing a specific option. The factors $α_j$ and $β*p_j$ in the utility calculation represent the characteristics of each choice $j$ and their influence on the consumer's decision. The parameter $α_j$ captures the inherent preference for choice $j$ (the \"intercept\" term), and $β*p_j$ reflects how the price of choice $j$ influences its utility (with $β$ being the price sensitivity).\n",
    "\n",
    "* $U_ij$ represents unobserved factors that could also influence the consumer's decision. The use of a standard type I extreme value distribution for U_ij is a standard assumption in discrete choice models and leads to the logit form for the choice probabilities.\n",
    "\n",
    "* In summary, the estimation of θ reflects an analysis of consumer choice behavior under a specific scenario (price alteration of choice 1) based on the given utility model. The implications of the estimated θ could be used for various economic applications such as market prediction, pricing strategy, demand estimation, policy design, etc."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0dcf4605",
   "metadata": {},
   "source": [
    "## 5. Montecarlo Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "214efd44-71a4-4bc4-b45e-d2370167d7f5",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(tidyverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd9f563b",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 5000 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>beta_hat</th><th scope=col>theta_hat</th><th scope=col>n</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>-0.8462573</td><td>0.4799976</td><td>n =  50</td></tr>\n",
       "\t<tr><td>-0.8482505</td><td>0.3800309</td><td>n =  50</td></tr>\n",
       "\t<tr><td>-0.9081915</td><td>0.2799987</td><td>n =  50</td></tr>\n",
       "\t<tr><td>-0.8799594</td><td>0.4999987</td><td>n =  50</td></tr>\n",
       "\t<tr><td>-0.8346447</td><td>0.3599992</td><td>n =  50</td></tr>\n",
       "\t<tr><td>-0.8831188</td><td>0.3199457</td><td>n =  50</td></tr>\n",
       "\t<tr><td>-0.8363292</td><td>0.3400760</td><td>n =  50</td></tr>\n",
       "\t<tr><td>-0.8943927</td><td>0.3600071</td><td>n =  50</td></tr>\n",
       "\t<tr><td>-0.8338162</td><td>0.4399839</td><td>n =  50</td></tr>\n",
       "\t<tr><td>-0.8943927</td><td>0.3600071</td><td>n =  50</td></tr>\n",
       "\t<tr><td>-0.8369641</td><td>0.3799958</td><td>n =  50</td></tr>\n",
       "\t<tr><td>-0.8831188</td><td>0.3199457</td><td>n =  50</td></tr>\n",
       "\t<tr><td>-0.8420102</td><td>0.3800265</td><td>n =  50</td></tr>\n",
       "\t<tr><td>-0.8560342</td><td>0.5000868</td><td>n =  50</td></tr>\n",
       "\t<tr><td>-0.8975852</td><td>0.3400066</td><td>n =  50</td></tr>\n",
       "\t<tr><td>-0.8697284</td><td>0.4400688</td><td>n =  50</td></tr>\n",
       "\t<tr><td>-0.8560342</td><td>0.5000868</td><td>n =  50</td></tr>\n",
       "\t<tr><td>-0.8802547</td><td>0.3599991</td><td>n =  50</td></tr>\n",
       "\t<tr><td>-0.8415412</td><td>0.3000093</td><td>n =  50</td></tr>\n",
       "\t<tr><td>-0.9170031</td><td>0.2800061</td><td>n =  50</td></tr>\n",
       "\t<tr><td>-0.8578749</td><td>0.4200034</td><td>n =  50</td></tr>\n",
       "\t<tr><td>-0.8786198</td><td>0.3399295</td><td>n =  50</td></tr>\n",
       "\t<tr><td>-0.8310138</td><td>0.3599980</td><td>n =  50</td></tr>\n",
       "\t<tr><td>-0.8446424</td><td>0.3600645</td><td>n =  50</td></tr>\n",
       "\t<tr><td>-0.8855834</td><td>0.3999989</td><td>n =  50</td></tr>\n",
       "\t<tr><td>-0.8880180</td><td>0.3599994</td><td>n =  50</td></tr>\n",
       "\t<tr><td>-0.8832549</td><td>0.3799994</td><td>n =  50</td></tr>\n",
       "\t<tr><td>-0.8346447</td><td>0.3599992</td><td>n =  50</td></tr>\n",
       "\t<tr><td>-0.8406675</td><td>0.4799421</td><td>n =  50</td></tr>\n",
       "\t<tr><td>-0.8365010</td><td>0.4199724</td><td>n =  50</td></tr>\n",
       "\t<tr><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><td>-0.9974609</td><td>0.4115647</td><td>n =  5000</td></tr>\n",
       "\t<tr><td>-0.9892040</td><td>0.3969505</td><td>n =  5000</td></tr>\n",
       "\t<tr><td>-1.0002795</td><td>0.3985638</td><td>n =  5000</td></tr>\n",
       "\t<tr><td>-0.9827875</td><td>0.4051464</td><td>n =  5000</td></tr>\n",
       "\t<tr><td>-1.0131526</td><td>0.4081801</td><td>n =  5000</td></tr>\n",
       "\t<tr><td>-1.0035651</td><td>0.3989675</td><td>n =  5000</td></tr>\n",
       "\t<tr><td>-0.8926350</td><td>0.3909997</td><td>n =  5000</td></tr>\n",
       "\t<tr><td>-1.0056087</td><td>0.4139738</td><td>n =  5000</td></tr>\n",
       "\t<tr><td>-0.9976703</td><td>0.4017628</td><td>n =  5000</td></tr>\n",
       "\t<tr><td>-1.0030712</td><td>0.3887608</td><td>n =  5000</td></tr>\n",
       "\t<tr><td>-0.9977913</td><td>0.3961598</td><td>n =  5000</td></tr>\n",
       "\t<tr><td>-0.9851465</td><td>0.4081489</td><td>n =  5000</td></tr>\n",
       "\t<tr><td>-0.9855536</td><td>0.4073502</td><td>n =  5000</td></tr>\n",
       "\t<tr><td>-0.9771601</td><td>0.4025384</td><td>n =  5000</td></tr>\n",
       "\t<tr><td>-1.0802087</td><td>0.3757942</td><td>n =  5000</td></tr>\n",
       "\t<tr><td>-1.0183056</td><td>0.4017816</td><td>n =  5000</td></tr>\n",
       "\t<tr><td>-0.9776603</td><td>0.4017388</td><td>n =  5000</td></tr>\n",
       "\t<tr><td>-1.0320551</td><td>0.4005887</td><td>n =  5000</td></tr>\n",
       "\t<tr><td>-0.9703704</td><td>0.3923251</td><td>n =  5000</td></tr>\n",
       "\t<tr><td>-0.9941899</td><td>0.4049603</td><td>n =  5000</td></tr>\n",
       "\t<tr><td>-0.9786892</td><td>0.4015400</td><td>n =  5000</td></tr>\n",
       "\t<tr><td>-0.9944004</td><td>0.3937545</td><td>n =  5000</td></tr>\n",
       "\t<tr><td>-1.0411982</td><td>0.3959909</td><td>n =  5000</td></tr>\n",
       "\t<tr><td>-0.9800155</td><td>0.3965392</td><td>n =  5000</td></tr>\n",
       "\t<tr><td>-0.9899476</td><td>0.4079561</td><td>n =  5000</td></tr>\n",
       "\t<tr><td>-1.0081568</td><td>0.4013732</td><td>n =  5000</td></tr>\n",
       "\t<tr><td>-1.0102416</td><td>0.4017752</td><td>n =  5000</td></tr>\n",
       "\t<tr><td>-1.0026767</td><td>0.4057699</td><td>n =  5000</td></tr>\n",
       "\t<tr><td>-1.0001474</td><td>0.4055672</td><td>n =  5000</td></tr>\n",
       "\t<tr><td>-0.9926267</td><td>0.4095594</td><td>n =  5000</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 5000 × 3\n",
       "\\begin{tabular}{lll}\n",
       " beta\\_hat & theta\\_hat & n\\\\\n",
       " <dbl> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t -0.8462573 & 0.4799976 & n =  50\\\\\n",
       "\t -0.8482505 & 0.3800309 & n =  50\\\\\n",
       "\t -0.9081915 & 0.2799987 & n =  50\\\\\n",
       "\t -0.8799594 & 0.4999987 & n =  50\\\\\n",
       "\t -0.8346447 & 0.3599992 & n =  50\\\\\n",
       "\t -0.8831188 & 0.3199457 & n =  50\\\\\n",
       "\t -0.8363292 & 0.3400760 & n =  50\\\\\n",
       "\t -0.8943927 & 0.3600071 & n =  50\\\\\n",
       "\t -0.8338162 & 0.4399839 & n =  50\\\\\n",
       "\t -0.8943927 & 0.3600071 & n =  50\\\\\n",
       "\t -0.8369641 & 0.3799958 & n =  50\\\\\n",
       "\t -0.8831188 & 0.3199457 & n =  50\\\\\n",
       "\t -0.8420102 & 0.3800265 & n =  50\\\\\n",
       "\t -0.8560342 & 0.5000868 & n =  50\\\\\n",
       "\t -0.8975852 & 0.3400066 & n =  50\\\\\n",
       "\t -0.8697284 & 0.4400688 & n =  50\\\\\n",
       "\t -0.8560342 & 0.5000868 & n =  50\\\\\n",
       "\t -0.8802547 & 0.3599991 & n =  50\\\\\n",
       "\t -0.8415412 & 0.3000093 & n =  50\\\\\n",
       "\t -0.9170031 & 0.2800061 & n =  50\\\\\n",
       "\t -0.8578749 & 0.4200034 & n =  50\\\\\n",
       "\t -0.8786198 & 0.3399295 & n =  50\\\\\n",
       "\t -0.8310138 & 0.3599980 & n =  50\\\\\n",
       "\t -0.8446424 & 0.3600645 & n =  50\\\\\n",
       "\t -0.8855834 & 0.3999989 & n =  50\\\\\n",
       "\t -0.8880180 & 0.3599994 & n =  50\\\\\n",
       "\t -0.8832549 & 0.3799994 & n =  50\\\\\n",
       "\t -0.8346447 & 0.3599992 & n =  50\\\\\n",
       "\t -0.8406675 & 0.4799421 & n =  50\\\\\n",
       "\t -0.8365010 & 0.4199724 & n =  50\\\\\n",
       "\t ⋮ & ⋮ & ⋮\\\\\n",
       "\t -0.9974609 & 0.4115647 & n =  5000\\\\\n",
       "\t -0.9892040 & 0.3969505 & n =  5000\\\\\n",
       "\t -1.0002795 & 0.3985638 & n =  5000\\\\\n",
       "\t -0.9827875 & 0.4051464 & n =  5000\\\\\n",
       "\t -1.0131526 & 0.4081801 & n =  5000\\\\\n",
       "\t -1.0035651 & 0.3989675 & n =  5000\\\\\n",
       "\t -0.8926350 & 0.3909997 & n =  5000\\\\\n",
       "\t -1.0056087 & 0.4139738 & n =  5000\\\\\n",
       "\t -0.9976703 & 0.4017628 & n =  5000\\\\\n",
       "\t -1.0030712 & 0.3887608 & n =  5000\\\\\n",
       "\t -0.9977913 & 0.3961598 & n =  5000\\\\\n",
       "\t -0.9851465 & 0.4081489 & n =  5000\\\\\n",
       "\t -0.9855536 & 0.4073502 & n =  5000\\\\\n",
       "\t -0.9771601 & 0.4025384 & n =  5000\\\\\n",
       "\t -1.0802087 & 0.3757942 & n =  5000\\\\\n",
       "\t -1.0183056 & 0.4017816 & n =  5000\\\\\n",
       "\t -0.9776603 & 0.4017388 & n =  5000\\\\\n",
       "\t -1.0320551 & 0.4005887 & n =  5000\\\\\n",
       "\t -0.9703704 & 0.3923251 & n =  5000\\\\\n",
       "\t -0.9941899 & 0.4049603 & n =  5000\\\\\n",
       "\t -0.9786892 & 0.4015400 & n =  5000\\\\\n",
       "\t -0.9944004 & 0.3937545 & n =  5000\\\\\n",
       "\t -1.0411982 & 0.3959909 & n =  5000\\\\\n",
       "\t -0.9800155 & 0.3965392 & n =  5000\\\\\n",
       "\t -0.9899476 & 0.4079561 & n =  5000\\\\\n",
       "\t -1.0081568 & 0.4013732 & n =  5000\\\\\n",
       "\t -1.0102416 & 0.4017752 & n =  5000\\\\\n",
       "\t -1.0026767 & 0.4057699 & n =  5000\\\\\n",
       "\t -1.0001474 & 0.4055672 & n =  5000\\\\\n",
       "\t -0.9926267 & 0.4095594 & n =  5000\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 5000 × 3\n",
       "\n",
       "| beta_hat &lt;dbl&gt; | theta_hat &lt;dbl&gt; | n &lt;chr&gt; |\n",
       "|---|---|---|\n",
       "| -0.8462573 | 0.4799976 | n =  50 |\n",
       "| -0.8482505 | 0.3800309 | n =  50 |\n",
       "| -0.9081915 | 0.2799987 | n =  50 |\n",
       "| -0.8799594 | 0.4999987 | n =  50 |\n",
       "| -0.8346447 | 0.3599992 | n =  50 |\n",
       "| -0.8831188 | 0.3199457 | n =  50 |\n",
       "| -0.8363292 | 0.3400760 | n =  50 |\n",
       "| -0.8943927 | 0.3600071 | n =  50 |\n",
       "| -0.8338162 | 0.4399839 | n =  50 |\n",
       "| -0.8943927 | 0.3600071 | n =  50 |\n",
       "| -0.8369641 | 0.3799958 | n =  50 |\n",
       "| -0.8831188 | 0.3199457 | n =  50 |\n",
       "| -0.8420102 | 0.3800265 | n =  50 |\n",
       "| -0.8560342 | 0.5000868 | n =  50 |\n",
       "| -0.8975852 | 0.3400066 | n =  50 |\n",
       "| -0.8697284 | 0.4400688 | n =  50 |\n",
       "| -0.8560342 | 0.5000868 | n =  50 |\n",
       "| -0.8802547 | 0.3599991 | n =  50 |\n",
       "| -0.8415412 | 0.3000093 | n =  50 |\n",
       "| -0.9170031 | 0.2800061 | n =  50 |\n",
       "| -0.8578749 | 0.4200034 | n =  50 |\n",
       "| -0.8786198 | 0.3399295 | n =  50 |\n",
       "| -0.8310138 | 0.3599980 | n =  50 |\n",
       "| -0.8446424 | 0.3600645 | n =  50 |\n",
       "| -0.8855834 | 0.3999989 | n =  50 |\n",
       "| -0.8880180 | 0.3599994 | n =  50 |\n",
       "| -0.8832549 | 0.3799994 | n =  50 |\n",
       "| -0.8346447 | 0.3599992 | n =  50 |\n",
       "| -0.8406675 | 0.4799421 | n =  50 |\n",
       "| -0.8365010 | 0.4199724 | n =  50 |\n",
       "| ⋮ | ⋮ | ⋮ |\n",
       "| -0.9974609 | 0.4115647 | n =  5000 |\n",
       "| -0.9892040 | 0.3969505 | n =  5000 |\n",
       "| -1.0002795 | 0.3985638 | n =  5000 |\n",
       "| -0.9827875 | 0.4051464 | n =  5000 |\n",
       "| -1.0131526 | 0.4081801 | n =  5000 |\n",
       "| -1.0035651 | 0.3989675 | n =  5000 |\n",
       "| -0.8926350 | 0.3909997 | n =  5000 |\n",
       "| -1.0056087 | 0.4139738 | n =  5000 |\n",
       "| -0.9976703 | 0.4017628 | n =  5000 |\n",
       "| -1.0030712 | 0.3887608 | n =  5000 |\n",
       "| -0.9977913 | 0.3961598 | n =  5000 |\n",
       "| -0.9851465 | 0.4081489 | n =  5000 |\n",
       "| -0.9855536 | 0.4073502 | n =  5000 |\n",
       "| -0.9771601 | 0.4025384 | n =  5000 |\n",
       "| -1.0802087 | 0.3757942 | n =  5000 |\n",
       "| -1.0183056 | 0.4017816 | n =  5000 |\n",
       "| -0.9776603 | 0.4017388 | n =  5000 |\n",
       "| -1.0320551 | 0.4005887 | n =  5000 |\n",
       "| -0.9703704 | 0.3923251 | n =  5000 |\n",
       "| -0.9941899 | 0.4049603 | n =  5000 |\n",
       "| -0.9786892 | 0.4015400 | n =  5000 |\n",
       "| -0.9944004 | 0.3937545 | n =  5000 |\n",
       "| -1.0411982 | 0.3959909 | n =  5000 |\n",
       "| -0.9800155 | 0.3965392 | n =  5000 |\n",
       "| -0.9899476 | 0.4079561 | n =  5000 |\n",
       "| -1.0081568 | 0.4013732 | n =  5000 |\n",
       "| -1.0102416 | 0.4017752 | n =  5000 |\n",
       "| -1.0026767 | 0.4057699 | n =  5000 |\n",
       "| -1.0001474 | 0.4055672 | n =  5000 |\n",
       "| -0.9926267 | 0.4095594 | n =  5000 |\n",
       "\n"
      ],
      "text/plain": [
       "     beta_hat   theta_hat n        \n",
       "1    -0.8462573 0.4799976 n =  50  \n",
       "2    -0.8482505 0.3800309 n =  50  \n",
       "3    -0.9081915 0.2799987 n =  50  \n",
       "4    -0.8799594 0.4999987 n =  50  \n",
       "5    -0.8346447 0.3599992 n =  50  \n",
       "6    -0.8831188 0.3199457 n =  50  \n",
       "7    -0.8363292 0.3400760 n =  50  \n",
       "8    -0.8943927 0.3600071 n =  50  \n",
       "9    -0.8338162 0.4399839 n =  50  \n",
       "10   -0.8943927 0.3600071 n =  50  \n",
       "11   -0.8369641 0.3799958 n =  50  \n",
       "12   -0.8831188 0.3199457 n =  50  \n",
       "13   -0.8420102 0.3800265 n =  50  \n",
       "14   -0.8560342 0.5000868 n =  50  \n",
       "15   -0.8975852 0.3400066 n =  50  \n",
       "16   -0.8697284 0.4400688 n =  50  \n",
       "17   -0.8560342 0.5000868 n =  50  \n",
       "18   -0.8802547 0.3599991 n =  50  \n",
       "19   -0.8415412 0.3000093 n =  50  \n",
       "20   -0.9170031 0.2800061 n =  50  \n",
       "21   -0.8578749 0.4200034 n =  50  \n",
       "22   -0.8786198 0.3399295 n =  50  \n",
       "23   -0.8310138 0.3599980 n =  50  \n",
       "24   -0.8446424 0.3600645 n =  50  \n",
       "25   -0.8855834 0.3999989 n =  50  \n",
       "26   -0.8880180 0.3599994 n =  50  \n",
       "27   -0.8832549 0.3799994 n =  50  \n",
       "28   -0.8346447 0.3599992 n =  50  \n",
       "29   -0.8406675 0.4799421 n =  50  \n",
       "30   -0.8365010 0.4199724 n =  50  \n",
       "⋮    ⋮          ⋮         ⋮        \n",
       "4971 -0.9974609 0.4115647 n =  5000\n",
       "4972 -0.9892040 0.3969505 n =  5000\n",
       "4973 -1.0002795 0.3985638 n =  5000\n",
       "4974 -0.9827875 0.4051464 n =  5000\n",
       "4975 -1.0131526 0.4081801 n =  5000\n",
       "4976 -1.0035651 0.3989675 n =  5000\n",
       "4977 -0.8926350 0.3909997 n =  5000\n",
       "4978 -1.0056087 0.4139738 n =  5000\n",
       "4979 -0.9976703 0.4017628 n =  5000\n",
       "4980 -1.0030712 0.3887608 n =  5000\n",
       "4981 -0.9977913 0.3961598 n =  5000\n",
       "4982 -0.9851465 0.4081489 n =  5000\n",
       "4983 -0.9855536 0.4073502 n =  5000\n",
       "4984 -0.9771601 0.4025384 n =  5000\n",
       "4985 -1.0802087 0.3757942 n =  5000\n",
       "4986 -1.0183056 0.4017816 n =  5000\n",
       "4987 -0.9776603 0.4017388 n =  5000\n",
       "4988 -1.0320551 0.4005887 n =  5000\n",
       "4989 -0.9703704 0.3923251 n =  5000\n",
       "4990 -0.9941899 0.4049603 n =  5000\n",
       "4991 -0.9786892 0.4015400 n =  5000\n",
       "4992 -0.9944004 0.3937545 n =  5000\n",
       "4993 -1.0411982 0.3959909 n =  5000\n",
       "4994 -0.9800155 0.3965392 n =  5000\n",
       "4995 -0.9899476 0.4079561 n =  5000\n",
       "4996 -1.0081568 0.4013732 n =  5000\n",
       "4997 -1.0102416 0.4017752 n =  5000\n",
       "4998 -1.0026767 0.4057699 n =  5000\n",
       "4999 -1.0001474 0.4055672 n =  5000\n",
       "5000 -0.9926267 0.4095594 n =  5000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# True parameter values\n",
    "true_alpha <- c(0, -0.5, 0, 1)\n",
    "true_beta <- -0.1  # some arbitrary value\n",
    "true_p <- c(0, 5, 10, 15)\n",
    "num_datasets <- 1000  # number of datasets to generate\n",
    "sample_sizes <- c(50, 100, 500, 1000, 5000)  # different sample sizes to test\n",
    "\n",
    "# Define the log likelihood function\n",
    "log_likelihood <- function(Y, alpha, beta, p) {\n",
    "  utilities <- alpha + beta * p\n",
    "  utilities <- utilities - max(utilities)  # for numerical stability\n",
    "  exp_utilities <- exp(utilities)\n",
    "  probabilities <- exp_utilities / sum(exp_utilities)\n",
    "  return(sum(log(probabilities[Y])))\n",
    "}\n",
    "\n",
    "# Optimization function to get the estimates\n",
    "optimize <- function(Y_i_sample, alpha, beta, p) {\n",
    "  # Define the objective function to be minimized (negative log-likelihood)\n",
    "  objective <- function(params) {\n",
    "    alpha <- params[1:4]  # first four parameters are alpha_j\n",
    "    beta <- params[5]  # last parameter is beta\n",
    "    return(-log_likelihood(Y_i_sample, alpha, beta, p))\n",
    "  }\n",
    "\n",
    "  # Initial guess for alpha and beta\n",
    "  initial_guess <- c(alpha, beta)\n",
    "\n",
    "  # Perform optimization\n",
    "  result <- optim(initial_guess, objective, method = \"BFGS\")\n",
    "\n",
    "  # Return the estimated alpha and beta\n",
    "  alpha_hat <- result$par[1:4]\n",
    "  beta_hat <- result$par[5]\n",
    "  return(list(alpha_hat = alpha_hat, beta_hat = beta_hat))\n",
    "}\n",
    "# Calculate theta hat function\n",
    "calculate_theta_hat <- function(alpha_hat, beta_hat, p) {\n",
    "  utilities <- alpha_hat + beta_hat * p\n",
    "  probabilities <- exp(utilities) / sum(exp(utilities))\n",
    "  return(probabilities[2])  # return the probability of option 1\n",
    "}\n",
    "\n",
    "simulation = function(n_size){\n",
    "    softmax <- function(x){\n",
    "        x / sum(x)\n",
    "    }\n",
    "    n_txt = paste(\"n = \", n_size)\n",
    "    sample_datasets = function(i){\n",
    "        Y_i_sample <- sample(c(0, 1, 2, 3), size = n_size, replace = TRUE, prob = softmax(true_alpha + true_beta * true_p))\n",
    "        opt = optimize(Y_i_sample, true_alpha, true_beta, true_p)\n",
    "        tibble(beta_hat = opt$beta_hat, theta_hat = calculate_theta_hat(opt$alpha_hat, opt$beta_hat, true_p), n = n_txt)\n",
    "    }\n",
    "    return(purrr::map_df(1:num_datasets, sample_datasets))\n",
    "}\n",
    "\n",
    "simulation_df = purrr::map_df(sample_sizes, simulation)\n",
    "simulation_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c9dbb09-1ed1-4413-8826-a64228b241be",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "theme_set(theme_minimal())\n",
    "ggplot(simulation_df) +\n",
    "    aes(beta_hat / 10, fill = n) +\n",
    "    geom_histogram(position = 'jitter', alpha = .5, bins = 30) +\n",
    "    geom_vline(xintercept = true_beta, color = \"red\") + \n",
    "    labs(title = \"Distribution of beta_hat estimates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "472ca125-7101-4964-84c0-9970cc5cfa40",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ggplot(simulation_df) +\n",
    "    aes(theta_hat, fill = n) +\n",
    "    geom_histogram(position = 'jitter', alpha = .5, bins = 30) +\n",
    "    labs(title = \"Distribution of theta_hat estimates\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1879ffc7",
   "metadata": {},
   "source": [
    "## 6. Discuss how you would construct confidence intervals for $\\beta_{hat}$ and $\\theta_{hat}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e72d3474",
   "metadata": {},
   "source": [
    "To construct confidence intervals for beta_hat and theta_hat, we can use the estimated standard errors of the estimates. In large samples, by the Central Limit Theorem, beta_hat and theta_hat are approximately normally distributed. Therefore, you can use the following formulas for the lower and upper limits of the 95% confidence interval: \n",
    "\n",
    "* lower_limit = estimate - 1.96 * standard_error\n",
    "* upper_limit = estimate + 1.96 * standard_error\n",
    "\n",
    "In this case, however, the standard errors of beta_hat and theta_hat are not readily available. We could estimate these by bootstrapping: resample the data with replacement, calculate beta_hat and theta_hat for each resampled dataset, and then calculate the standard deviation of these bootstrapped estimates.\n",
    "\n",
    "The following code implements a Monte Carlo study that checks whether these bootstrapped 95% confidence intervals cover the true parameter values 95% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4768c6ac-c380-452e-8415-348c3e7f85ba",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"n =  50\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \u001b[32m■■■■■■■■■■■                     \u001b[39m  33% |  ETA:  2m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"n =  100\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \u001b[32m■■■■■■■■■■■■■■■■■■■■■           \u001b[39m  67% |  ETA:  1m\n"
     ]
    }
   ],
   "source": [
    "sample_df = tibble(esti_hat = NA, value = NA, n = \"\", bt_bottom = 1, bt_upper = 1)\n",
    "sample_sizes <- c(50, 100, 500)\n",
    "num_bootstrap_samples = 50\n",
    "simulation_ci = function(n_size){\n",
    "    \n",
    "    softmax <- function(x){\n",
    "        x / sum(x)\n",
    "    }\n",
    "    n_txt = paste(\"n = \", n_size)\n",
    "    print(n_txt)\n",
    "    sample_datasets = function(i){\n",
    "        Y_i_sample <- sample(c(0, 1, 2, 3), size = n_size, replace = TRUE, prob = softmax(true_alpha + true_beta * true_p))\n",
    "        opt = optimize(Y_i_sample, true_alpha, true_beta, true_p)\n",
    "\n",
    "        alpha_hat = opt$alpha_hat\n",
    "        beta_hat = opt$beta_hat\n",
    "        theta_hat = calculate_theta_hat(opt$alpha_hat, opt$beta_hat, true_p)\n",
    "        bt_beta_hats = c()\n",
    "        bt_theta_hats = c()\n",
    "        \n",
    "        for(bt in 1:num_bootstrap_samples){\n",
    "            bootstrap_sample = sample(Y_i_sample, size = n_size, replace = T)\n",
    "            opt_bt = optimize(bootstrap_sample, alpha_hat, beta_hat, true_p)\n",
    "            bt_alpha_hat = opt_bt$alpha_hat\n",
    "            bt_beta_hat = opt_bt$beta_hat\n",
    "            bt_theta_hat = calculate_theta_hat(bt_alpha_hat, bt_beta_hat, true_p)\n",
    "    \n",
    "            bt_beta_hats = append(bt_beta_hats, bt_beta_hat)\n",
    "            bt_theta_hats = append(bt_theta_hats, bt_theta_hat)\n",
    "        }\n",
    "\n",
    "        bt_beta_ci = c(quantile(bt_beta_hats, probs = c(0.025, 0.975))) / 10\n",
    "        bt_theta_ci = c(quantile(bt_theta_hats, probs = c(0.025, 0.975))) / 10\n",
    "        \n",
    "        sample_df = sample_df |> add_row(esti_hat = \"beta\", value = beta_hat, n = n_txt, bt_bottom = bt_beta_ci[[1]], bt_upper = bt_beta_ci[[2]])\n",
    "        # sample_df = sample_df |> add_row(esti_hat = \"beta\", value = beta_hat, n = n_txt, bt_ci = list(bt_beta_hats))\n",
    "        sample_df = sample_df |> add_row(esti_hat = \"theta\", value = theta_hat, n = n_txt, bt_bottom = bt_theta_ci[[1]], bt_upper = bt_theta_ci[[2]])\n",
    "        # sample_df = sample_df |> add_row(esti_hat = \"theta\", value = theta_hat, n = n_txt, bt_ci = list(bt_theta_hats))\n",
    "        # list(bt_beta_hats, bt_theta_hats)\n",
    "    }\n",
    "    \n",
    "    return(purrr::map_df(1:num_datasets, sample_datasets)|> drop_na(value) )\n",
    "}\n",
    "simulation_df = purrr::map_df(sample_sizes, simulation_ci, .progress = T)\n",
    "simulation_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41af73b7-205a-450c-9cf1-60ca3af82000",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "simulation_df |> group_by(n, esti_hat) |> summarise(across(everything(), mean)) |> dplyr::select(!value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6e9b7f-c112-41a4-ac67-92bb485ae612",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
